# -*- coding: utf-8 -*-
"""simba_test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IfM3Qu-qGbFNgKu5_F7yYiOA_HCJ28E0
"""

# -*- coding: utf-8 -*-
"""simba_test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IfM3Qu-qGbFNgKu5_F7yYiOA_HCJ28E0
"""

import argparse
import json

import joblib
import numpy as np
import torch
import tqdm

import simba
from src.datasets import make_dataset
from src.models import TransformerClassification, CNNClassification, LSTMClassification
from src.utils import str2torch
from src.search_vectors import CartesianSearchVectors

BUDGET = 8.0

MODELS = {
    'cnn': CNNClassification,
    'transformer': TransformerClassification,
    'lstm': LSTMClassification
    }


def test(config, weights, step_size=BUDGET/50, budget=BUDGET):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    config['train']['optimizer'] = str2torch(config['train']['optimizer'])

    _, test_dataset, _, _ = make_dataset(config, args.data, return_loader=False)
    model = MODELS[config['model']['name']]
    model = model(config).to(device)
    weights = torch.load(weights, map_location='cpu')
    model.load_state_dict(weights)

    iters = []
    for i in tqdm.tqdm(range(len(test_dataset))):
        test_sample, label = test_dataset[i]
        test_sample = torch.from_numpy(test_sample).unsqueeze(1).to(device)
	basis = CartesianSearchVectors(test_sample.size())
        _, _, steps, _, _:q = simba.simba(test_sample, model, int(label), basis=basis, step_size=BUDGET / 50, budget=BUDGET)

        iters.append(steps)
    return iters


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument("config", type=str, help="train json config")
    parser.add_argument("weights", type=str, help="weights of model")
    parser.add_argument("--data", type=str, required=False, default='data/FordA', help="path to data folder")

    args = parser.parse_args()

    with open(args.config) as f:
        config =  json.load(f)

    iters = test(config, args.weights)
    unique, counts = np.unique(iters, return_counts=True)
    print('distribution of number of iterations till inversion of label')
    print(unique)
    print(counts)