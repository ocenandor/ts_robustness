{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21deb97e-6b79-4374-914e-7d79a8565c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import wandb\n",
    "from ignite.contrib.handlers import wandb_logger\n",
    "from ignite.engine import (Engine, Events, create_supervised_evaluator,\n",
    "                           create_supervised_trainer)\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.handlers.param_scheduler import LRScheduler\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.datasets import FordDataset\n",
    "from src.models import LSTMClassification\n",
    "from src.utils import build_optimizer, str2torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3178f9a7-d2bb-4af0-80e8-5b2b59e75d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/lstm_config.json') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d70cd6e9-6add-4087-ac03-214b50ecaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/FordA/FordA_TRAIN.arff\"\n",
    "test_path = \"../data/FordA/FordA_TEST.arff\"\n",
    "\n",
    "train_dataset = FordDataset(train_path, config['data'])\n",
    "test_dataset = FordDataset(test_path, config['data'])\n",
    "\n",
    "idx = np.arange(len(train_dataset))\n",
    "idx_train, idx_val = train_test_split(idx, train_size=0.8, stratify=train_dataset.labels, random_state=config['random_state'])\n",
    "\n",
    "train_sampler = SubsetRandomSampler(idx_train)\n",
    "val_sampler = SubsetRandomSampler(idx_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=128, sampler=val_sampler)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4590d65-4cfa-43af-b4ac-26b0021c27f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgamma_function\u001b[0m (\u001b[33mts-robustness\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Study\\Skoltech\\MachineLearning\\ts_robustness\\notebooks\\wandb\\run-20240312_211437-qqtsxdyp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ts-robustness/ml-course/runs/qqtsxdyp' target=\"_blank\">usual-elevator-306</a></strong> to <a href='https://wandb.ai/ts-robustness/ml-course' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ts-robustness/ml-course' target=\"_blank\">https://wandb.ai/ts-robustness/ml-course</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ts-robustness/ml-course/runs/qqtsxdyp' target=\"_blank\">https://wandb.ai/ts-robustness/ml-course/runs/qqtsxdyp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize your model\n",
    "wandb.init(entity='ts-robustness', project='ml-course', config=config)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config['train']['optimizer'] = str2torch(config['train']['optimizer'])\n",
    "print('device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db106f3d-46d4-4214-8ca8-3bdc240df94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassification(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb31168-4015-43d3-a5d4-07ba6d587d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Avg loss: 0.6915\n",
      "Training Results - Avg loss: 0.6923\n",
      "Training Results - Avg loss: 0.6951\n",
      "Training Results - Avg loss: 0.6929\n",
      "Training Results - Avg loss: 0.6930\n",
      "Training Results - Avg loss: 0.6947\n",
      "Training Results - Avg loss: 0.6924\n",
      "Training Results - Avg loss: 0.6938\n",
      "Training Results - Avg loss: 0.6927\n",
      "Training Results - Avg loss: 0.6928\n",
      "Training Results - Avg loss: 0.6926\n",
      "Training Results - Avg loss: 0.6922\n",
      "Training Results - Avg loss: 0.6919\n",
      "Training Results - Avg loss: 0.6909\n",
      "Training Results - Avg loss: 0.6926\n",
      "Training Results - Avg loss: 0.6925\n",
      "Training Results - Avg loss: 0.6931\n",
      "Training Results - Avg loss: 0.6922\n",
      "Training Results - Avg loss: 0.6913\n",
      "Training Results - Avg loss: 0.6925\n",
      "Training Results - Avg loss: 0.6901\n",
      "Training Results - Avg loss: 0.6942\n",
      "Training Results - Avg loss: 0.6914\n",
      "Training Results - Epoch: 1  Avg accuracy: 0.53 Avg loss: 0.6915\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.51 Avg loss: 0.6917\n",
      "Training Results - Avg loss: 0.6923\n",
      "Training Results - Avg loss: 0.6911\n",
      "Training Results - Avg loss: 0.6899\n",
      "Training Results - Avg loss: 0.6914\n",
      "Training Results - Avg loss: 0.6940\n",
      "Training Results - Avg loss: 0.6908\n",
      "Training Results - Avg loss: 0.6868\n",
      "Training Results - Avg loss: 0.6895\n",
      "Training Results - Avg loss: 0.6924\n",
      "Training Results - Avg loss: 0.6905\n",
      "Training Results - Avg loss: 0.6896\n",
      "Training Results - Avg loss: 0.6886\n",
      "Training Results - Avg loss: 0.6888\n",
      "Training Results - Avg loss: 0.6921\n",
      "Training Results - Avg loss: 0.6859\n",
      "Training Results - Avg loss: 0.6909\n",
      "Training Results - Avg loss: 0.6904\n",
      "Training Results - Avg loss: 0.6916\n",
      "Training Results - Avg loss: 0.6853\n",
      "Training Results - Avg loss: 0.6854\n",
      "Training Results - Avg loss: 0.6888\n",
      "Training Results - Avg loss: 0.6935\n",
      "Training Results - Avg loss: 0.6859\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.57 Avg loss: 0.6872\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.55 Avg loss: 0.6884\n",
      "Training Results - Avg loss: 0.6868\n",
      "Training Results - Avg loss: 0.6878\n",
      "Training Results - Avg loss: 0.6876\n",
      "Training Results - Avg loss: 0.6906\n",
      "Training Results - Avg loss: 0.6838\n",
      "Training Results - Avg loss: 0.6823\n",
      "Training Results - Avg loss: 0.6839\n",
      "Training Results - Avg loss: 0.6844\n",
      "Training Results - Avg loss: 0.6813\n",
      "Training Results - Avg loss: 0.6832\n",
      "Training Results - Avg loss: 0.6846\n",
      "Training Results - Avg loss: 0.6819\n",
      "Training Results - Avg loss: 0.6756\n",
      "Training Results - Avg loss: 0.6760\n",
      "Training Results - Avg loss: 0.6798\n",
      "Training Results - Avg loss: 0.6823\n",
      "Training Results - Avg loss: 0.6842\n",
      "Training Results - Avg loss: 0.6768\n",
      "Training Results - Avg loss: 0.6793\n",
      "Training Results - Avg loss: 0.6811\n",
      "Training Results - Avg loss: 0.6858\n",
      "Training Results - Avg loss: 0.6695\n",
      "Training Results - Avg loss: 0.6774\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.65 Avg loss: 0.6716\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.58 Avg loss: 0.6785\n",
      "Training Results - Avg loss: 0.6738\n",
      "Training Results - Avg loss: 0.6598\n",
      "Training Results - Avg loss: 0.6701\n",
      "Training Results - Avg loss: 0.6728\n",
      "Training Results - Avg loss: 0.6708\n",
      "Training Results - Avg loss: 0.6632\n",
      "Training Results - Avg loss: 0.6680\n",
      "Training Results - Avg loss: 0.6624\n",
      "Training Results - Avg loss: 0.6515\n",
      "Training Results - Avg loss: 0.6387\n",
      "Training Results - Avg loss: 0.6464\n",
      "Training Results - Avg loss: 0.6610\n",
      "Training Results - Avg loss: 0.6698\n",
      "Training Results - Avg loss: 0.6457\n",
      "Training Results - Avg loss: 0.6351\n",
      "Training Results - Avg loss: 0.6595\n",
      "Training Results - Avg loss: 0.6373\n",
      "Training Results - Avg loss: 0.6545\n",
      "Training Results - Avg loss: 0.6245\n",
      "Training Results - Avg loss: 0.6383\n",
      "Training Results - Avg loss: 0.6297\n",
      "Training Results - Avg loss: 0.6296\n",
      "Training Results - Avg loss: 0.6373\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.70 Avg loss: 0.6177\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.63 Avg loss: 0.6405\n",
      "Training Results - Avg loss: 0.6183\n",
      "Training Results - Avg loss: 0.6030\n",
      "Training Results - Avg loss: 0.5884\n",
      "Training Results - Avg loss: 0.5978\n",
      "Training Results - Avg loss: 0.5984\n",
      "Training Results - Avg loss: 0.6120\n",
      "Training Results - Avg loss: 0.6050\n",
      "Training Results - Avg loss: 0.6026\n",
      "Training Results - Avg loss: 0.6122\n",
      "Training Results - Avg loss: 0.5683\n",
      "Training Results - Avg loss: 0.6153\n",
      "Training Results - Avg loss: 0.5711\n",
      "Training Results - Avg loss: 0.5862\n",
      "Training Results - Avg loss: 0.5501\n",
      "Training Results - Avg loss: 0.5763\n",
      "Training Results - Avg loss: 0.5354\n",
      "Training Results - Avg loss: 0.5750\n",
      "Training Results - Avg loss: 0.5774\n",
      "Training Results - Avg loss: 0.5448\n",
      "Training Results - Avg loss: 0.5123\n",
      "Training Results - Avg loss: 0.5764\n",
      "Training Results - Avg loss: 0.5229\n",
      "Training Results - Avg loss: 0.5330\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.77 Avg loss: 0.5152\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.69 Avg loss: 0.5751\n",
      "Training Results - Avg loss: 0.4778\n",
      "Training Results - Avg loss: 0.4902\n",
      "Training Results - Avg loss: 0.4854\n",
      "Training Results - Avg loss: 0.4897\n",
      "Training Results - Avg loss: 0.5430\n",
      "Training Results - Avg loss: 0.5119\n",
      "Training Results - Avg loss: 0.4614\n",
      "Training Results - Avg loss: 0.5532\n",
      "Training Results - Avg loss: 0.4358\n",
      "Training Results - Avg loss: 0.5390\n",
      "Training Results - Avg loss: 0.4378\n",
      "Training Results - Avg loss: 0.4993\n",
      "Training Results - Avg loss: 0.4678\n",
      "Training Results - Avg loss: 0.4579\n",
      "Training Results - Avg loss: 0.4954\n",
      "Training Results - Avg loss: 0.5168\n",
      "Training Results - Avg loss: 0.4390\n",
      "Training Results - Avg loss: 0.4638\n",
      "Training Results - Avg loss: 0.4606\n",
      "Training Results - Avg loss: 0.4756\n",
      "Training Results - Avg loss: 0.4897\n",
      "Training Results - Avg loss: 0.4531\n",
      "Training Results - Avg loss: 0.4077\n",
      "Training Results - Epoch: 6  Avg accuracy: 0.83 Avg loss: 0.4256\n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.72 Avg loss: 0.5425\n",
      "Training Results - Avg loss: 0.4826\n",
      "Training Results - Avg loss: 0.4348\n",
      "Training Results - Avg loss: 0.4420\n",
      "Training Results - Avg loss: 0.4768\n",
      "Training Results - Avg loss: 0.3885\n",
      "Training Results - Avg loss: 0.3816\n",
      "Training Results - Avg loss: 0.4376\n",
      "Training Results - Avg loss: 0.3609\n",
      "Training Results - Avg loss: 0.3553\n",
      "Training Results - Avg loss: 0.4096\n",
      "Training Results - Avg loss: 0.4486\n",
      "Training Results - Avg loss: 0.4471\n",
      "Training Results - Avg loss: 0.4143\n",
      "Training Results - Avg loss: 0.3902\n",
      "Training Results - Avg loss: 0.3464\n",
      "Training Results - Avg loss: 0.3806\n",
      "Training Results - Avg loss: 0.3968\n",
      "Training Results - Avg loss: 0.3765\n",
      "Training Results - Avg loss: 0.3855\n",
      "Training Results - Avg loss: 0.3841\n",
      "Training Results - Avg loss: 0.4069\n",
      "Training Results - Avg loss: 0.3750\n",
      "Training Results - Avg loss: 0.3546\n",
      "Training Results - Epoch: 7  Avg accuracy: 0.87 Avg loss: 0.3495\n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.73 Avg loss: 0.5240\n",
      "Training Results - Avg loss: 0.3364\n",
      "Training Results - Avg loss: 0.3776\n",
      "Training Results - Avg loss: 0.2970\n",
      "Training Results - Avg loss: 0.4119\n",
      "Training Results - Avg loss: 0.3599\n",
      "Training Results - Avg loss: 0.3663\n",
      "Training Results - Avg loss: 0.3419\n",
      "Training Results - Avg loss: 0.4480\n",
      "Training Results - Avg loss: 0.3166\n",
      "Training Results - Avg loss: 0.3138\n",
      "Training Results - Avg loss: 0.3745\n",
      "Training Results - Avg loss: 0.2713\n",
      "Training Results - Avg loss: 0.3205\n",
      "Training Results - Avg loss: 0.3233\n",
      "Training Results - Avg loss: 0.2894\n",
      "Training Results - Avg loss: 0.3678\n",
      "Training Results - Avg loss: 0.3954\n",
      "Training Results - Avg loss: 0.3301\n",
      "Training Results - Avg loss: 0.2678\n",
      "Training Results - Avg loss: 0.2742\n",
      "Training Results - Avg loss: 0.3026\n",
      "Training Results - Avg loss: 0.2940\n",
      "Training Results - Avg loss: 0.3591\n",
      "Training Results - Epoch: 8  Avg accuracy: 0.90 Avg loss: 0.2841\n",
      "Validation Results - Epoch: 8  Avg accuracy: 0.74 Avg loss: 0.5287\n",
      "Training Results - Avg loss: 0.2720\n",
      "Training Results - Avg loss: 0.2514\n",
      "Training Results - Avg loss: 0.3165\n",
      "Training Results - Avg loss: 0.2525\n",
      "Training Results - Avg loss: 0.2364\n",
      "Training Results - Avg loss: 0.2487\n",
      "Training Results - Avg loss: 0.2915\n",
      "Training Results - Avg loss: 0.3311\n",
      "Training Results - Avg loss: 0.2596\n",
      "Training Results - Avg loss: 0.2729\n",
      "Training Results - Avg loss: 0.3339\n",
      "Training Results - Avg loss: 0.2251\n",
      "Training Results - Avg loss: 0.2215\n",
      "Training Results - Avg loss: 0.3169\n",
      "Training Results - Avg loss: 0.2448\n",
      "Training Results - Avg loss: 0.2077\n",
      "Training Results - Avg loss: 0.2979\n",
      "Training Results - Avg loss: 0.3053\n",
      "Training Results - Avg loss: 0.2944\n",
      "Training Results - Avg loss: 0.2987\n",
      "Training Results - Avg loss: 0.2891\n",
      "Training Results - Avg loss: 0.2428\n",
      "Training Results - Avg loss: 0.2373\n",
      "Training Results - Epoch: 9  Avg accuracy: 0.93 Avg loss: 0.2211\n",
      "Validation Results - Epoch: 9  Avg accuracy: 0.75 Avg loss: 0.5238\n",
      "Training Results - Avg loss: 0.2853\n",
      "Training Results - Avg loss: 0.2188\n",
      "Training Results - Avg loss: 0.1816\n",
      "Training Results - Avg loss: 0.1882\n",
      "Training Results - Avg loss: 0.2305\n",
      "Training Results - Avg loss: 0.1506\n",
      "Training Results - Avg loss: 0.2229\n",
      "Training Results - Avg loss: 0.2303\n",
      "Training Results - Avg loss: 0.2623\n",
      "Training Results - Avg loss: 0.2035\n",
      "Training Results - Avg loss: 0.2514\n",
      "Training Results - Avg loss: 0.2579\n",
      "Training Results - Avg loss: 0.2257\n",
      "Training Results - Avg loss: 0.1087\n",
      "Training Results - Avg loss: 0.1965\n",
      "Training Results - Avg loss: 0.2232\n",
      "Training Results - Avg loss: 0.2617\n",
      "Training Results - Avg loss: 0.1908\n",
      "Training Results - Avg loss: 0.2100\n",
      "Training Results - Avg loss: 0.1860\n",
      "Training Results - Avg loss: 0.2445\n",
      "Training Results - Avg loss: 0.1485\n",
      "Training Results - Avg loss: 0.2523\n",
      "Training Results - Epoch: 10  Avg accuracy: 0.94 Avg loss: 0.1802\n",
      "Validation Results - Epoch: 10  Avg accuracy: 0.77 Avg loss: 0.5251\n",
      "Training Results - Avg loss: 0.1668\n",
      "Training Results - Avg loss: 0.1764\n",
      "Training Results - Avg loss: 0.1426\n",
      "Training Results - Avg loss: 0.1705\n",
      "Training Results - Avg loss: 0.1344\n",
      "Training Results - Avg loss: 0.1941\n",
      "Training Results - Avg loss: 0.1322\n",
      "Training Results - Avg loss: 0.1943\n",
      "Training Results - Avg loss: 0.1445\n",
      "Training Results - Avg loss: 0.1623\n",
      "Training Results - Avg loss: 0.1641\n",
      "Training Results - Avg loss: 0.1779\n",
      "Training Results - Avg loss: 0.1698\n",
      "Training Results - Avg loss: 0.1698\n",
      "Training Results - Avg loss: 0.1335\n",
      "Training Results - Avg loss: 0.1625\n",
      "Training Results - Avg loss: 0.2210\n",
      "Training Results - Avg loss: 0.1966\n",
      "Training Results - Avg loss: 0.2275\n",
      "Training Results - Avg loss: 0.1480\n",
      "Training Results - Avg loss: 0.1296\n",
      "Training Results - Avg loss: 0.2753\n",
      "Training Results - Avg loss: 0.1235\n",
      "Training Results - Epoch: 11  Avg accuracy: 0.96 Avg loss: 0.1360\n",
      "Validation Results - Epoch: 11  Avg accuracy: 0.76 Avg loss: 0.5219\n",
      "Training Results - Avg loss: 0.1435\n",
      "Training Results - Avg loss: 0.1162\n",
      "Training Results - Avg loss: 0.1047\n",
      "Training Results - Avg loss: 0.1656\n",
      "Training Results - Avg loss: 0.1739\n",
      "Training Results - Avg loss: 0.1306\n",
      "Training Results - Avg loss: 0.1483\n",
      "Training Results - Avg loss: 0.1036\n",
      "Training Results - Avg loss: 0.1015\n",
      "Training Results - Avg loss: 0.1319\n",
      "Training Results - Avg loss: 0.0996\n",
      "Training Results - Avg loss: 0.1055\n",
      "Training Results - Avg loss: 0.1455\n",
      "Training Results - Avg loss: 0.2195\n",
      "Training Results - Avg loss: 0.1203\n",
      "Training Results - Avg loss: 0.1382\n",
      "Training Results - Avg loss: 0.0876\n",
      "Training Results - Avg loss: 0.1078\n",
      "Training Results - Avg loss: 0.1915\n",
      "Training Results - Avg loss: 0.1579\n",
      "Training Results - Avg loss: 0.1310\n",
      "Training Results - Avg loss: 0.1462\n",
      "Training Results - Avg loss: 0.1310\n",
      "Training Results - Epoch: 12  Avg accuracy: 0.97 Avg loss: 0.1047\n",
      "Validation Results - Epoch: 12  Avg accuracy: 0.76 Avg loss: 0.5465\n",
      "Training Results - Avg loss: 0.1075\n",
      "Training Results - Avg loss: 0.1033\n",
      "Training Results - Avg loss: 0.1003\n",
      "Training Results - Avg loss: 0.0814\n",
      "Training Results - Avg loss: 0.0880\n",
      "Training Results - Avg loss: 0.1166\n",
      "Training Results - Avg loss: 0.1044\n",
      "Training Results - Avg loss: 0.0805\n",
      "Training Results - Avg loss: 0.0792\n",
      "Training Results - Avg loss: 0.1088\n",
      "Training Results - Avg loss: 0.1355\n",
      "Training Results - Avg loss: 0.0915\n",
      "Training Results - Avg loss: 0.1313\n",
      "Training Results - Avg loss: 0.1051\n",
      "Training Results - Avg loss: 0.1023\n",
      "Training Results - Avg loss: 0.0805\n",
      "Training Results - Avg loss: 0.1934\n",
      "Training Results - Avg loss: 0.0857\n",
      "Training Results - Avg loss: 0.0730\n",
      "Training Results - Avg loss: 0.0928\n",
      "Training Results - Avg loss: 0.1363\n",
      "Training Results - Avg loss: 0.0944\n",
      "Training Results - Avg loss: 0.2080\n",
      "Training Results - Epoch: 13  Avg accuracy: 0.98 Avg loss: 0.0897\n",
      "Validation Results - Epoch: 13  Avg accuracy: 0.78 Avg loss: 0.5601\n",
      "Training Results - Avg loss: 0.1414\n",
      "Training Results - Avg loss: 0.0511\n",
      "Training Results - Avg loss: 0.0509\n",
      "Training Results - Avg loss: 0.1455\n",
      "Training Results - Avg loss: 0.0907\n",
      "Training Results - Avg loss: 0.0601\n",
      "Training Results - Avg loss: 0.0864\n",
      "Training Results - Avg loss: 0.0891\n",
      "Training Results - Avg loss: 0.0752\n",
      "Training Results - Avg loss: 0.0531\n",
      "Training Results - Avg loss: 0.0605\n",
      "Training Results - Avg loss: 0.0644\n",
      "Training Results - Avg loss: 0.0612\n",
      "Training Results - Avg loss: 0.0674\n",
      "Training Results - Avg loss: 0.0746\n",
      "Training Results - Avg loss: 0.1063\n",
      "Training Results - Avg loss: 0.0572\n",
      "Training Results - Avg loss: 0.0725\n",
      "Training Results - Avg loss: 0.0473\n",
      "Training Results - Avg loss: 0.0710\n",
      "Training Results - Avg loss: 0.0703\n",
      "Training Results - Avg loss: 0.1114\n",
      "Training Results - Avg loss: 0.1024\n",
      "Training Results - Epoch: 14  Avg accuracy: 0.99 Avg loss: 0.0635\n",
      "Validation Results - Epoch: 14  Avg accuracy: 0.78 Avg loss: 0.6111\n",
      "Training Results - Avg loss: 0.0761\n",
      "Training Results - Avg loss: 0.0655\n",
      "Training Results - Avg loss: 0.0545\n",
      "Training Results - Avg loss: 0.0329\n",
      "Training Results - Avg loss: 0.0532\n",
      "Training Results - Avg loss: 0.1028\n",
      "Training Results - Avg loss: 0.0570\n",
      "Training Results - Avg loss: 0.0281\n",
      "Training Results - Avg loss: 0.0797\n",
      "Training Results - Avg loss: 0.0387\n",
      "Training Results - Avg loss: 0.0544\n",
      "Training Results - Avg loss: 0.0568\n",
      "Training Results - Avg loss: 0.0338\n",
      "Training Results - Avg loss: 0.0398\n",
      "Training Results - Avg loss: 0.0493\n",
      "Training Results - Avg loss: 0.0694\n",
      "Training Results - Avg loss: 0.0725\n",
      "Training Results - Avg loss: 0.0686\n",
      "Training Results - Avg loss: 0.0865\n",
      "Training Results - Avg loss: 0.0562\n",
      "Training Results - Avg loss: 0.0405\n",
      "Training Results - Avg loss: 0.1018\n",
      "Training Results - Avg loss: 0.1353\n",
      "Training Results - Epoch: 15  Avg accuracy: 0.99 Avg loss: 0.0480\n",
      "Validation Results - Epoch: 15  Avg accuracy: 0.77 Avg loss: 0.6075\n",
      "Training Results - Avg loss: 0.0386\n",
      "Training Results - Avg loss: 0.0386\n",
      "Training Results - Avg loss: 0.0328\n",
      "Training Results - Avg loss: 0.0912\n",
      "Training Results - Avg loss: 0.0770\n",
      "Training Results - Avg loss: 0.0607\n",
      "Training Results - Avg loss: 0.0294\n",
      "Training Results - Avg loss: 0.0545\n",
      "Training Results - Avg loss: 0.0332\n",
      "Training Results - Avg loss: 0.0277\n",
      "Training Results - Avg loss: 0.0548\n",
      "Training Results - Avg loss: 0.0620\n",
      "Training Results - Avg loss: 0.0465\n",
      "Training Results - Avg loss: 0.0328\n",
      "Training Results - Avg loss: 0.0279\n",
      "Training Results - Avg loss: 0.0952\n",
      "Training Results - Avg loss: 0.0498\n",
      "Training Results - Avg loss: 0.0491\n",
      "Training Results - Avg loss: 0.0396\n",
      "Training Results - Avg loss: 0.0462\n",
      "Training Results - Avg loss: 0.0637\n",
      "Training Results - Avg loss: 0.0555\n",
      "Training Results - Avg loss: 0.0327\n",
      "Training Results - Epoch: 16  Avg accuracy: 1.00 Avg loss: 0.0371\n",
      "Validation Results - Epoch: 16  Avg accuracy: 0.77 Avg loss: 0.6607\n",
      "Training Results - Avg loss: 0.0511\n",
      "Training Results - Avg loss: 0.0630\n",
      "Training Results - Avg loss: 0.0281\n",
      "Training Results - Avg loss: 0.0364\n",
      "Training Results - Avg loss: 0.0301\n",
      "Training Results - Avg loss: 0.0702\n",
      "Training Results - Avg loss: 0.0311\n",
      "Training Results - Avg loss: 0.0364\n",
      "Training Results - Avg loss: 0.0531\n",
      "Training Results - Avg loss: 0.0465\n",
      "Training Results - Avg loss: 0.0265\n",
      "Training Results - Avg loss: 0.0487\n",
      "Training Results - Avg loss: 0.0404\n",
      "Training Results - Avg loss: 0.0221\n",
      "Training Results - Avg loss: 0.0287\n",
      "Training Results - Avg loss: 0.0407\n",
      "Training Results - Avg loss: 0.0288\n",
      "Training Results - Avg loss: 0.0316\n",
      "Training Results - Avg loss: 0.0530\n",
      "Training Results - Avg loss: 0.0432\n",
      "Training Results - Avg loss: 0.0418\n",
      "Training Results - Avg loss: 0.0445\n",
      "Training Results - Avg loss: 0.0371\n",
      "Training Results - Epoch: 17  Avg accuracy: 0.99 Avg loss: 0.0310\n",
      "Validation Results - Epoch: 17  Avg accuracy: 0.79 Avg loss: 0.7008\n",
      "Training Results - Avg loss: 0.0320\n",
      "Training Results - Avg loss: 0.0395\n",
      "Training Results - Avg loss: 0.0358\n",
      "Training Results - Avg loss: 0.0247\n",
      "Training Results - Avg loss: 0.0291\n",
      "Training Results - Avg loss: 0.0290\n",
      "Training Results - Avg loss: 0.0252\n",
      "Training Results - Avg loss: 0.0317\n",
      "Training Results - Avg loss: 0.0356\n",
      "Training Results - Avg loss: 0.0301\n",
      "Training Results - Avg loss: 0.0309\n",
      "Training Results - Avg loss: 0.0353\n",
      "Training Results - Avg loss: 0.0257\n",
      "Training Results - Avg loss: 0.0293\n",
      "Training Results - Avg loss: 0.0304\n",
      "Training Results - Avg loss: 0.0243\n",
      "Training Results - Avg loss: 0.0486\n",
      "Training Results - Avg loss: 0.0392\n",
      "Training Results - Avg loss: 0.0159\n",
      "Training Results - Avg loss: 0.0556\n",
      "Training Results - Avg loss: 0.0322\n",
      "Training Results - Avg loss: 0.0410\n",
      "Training Results - Avg loss: 0.0287\n",
      "Training Results - Epoch: 18  Avg accuracy: 1.00 Avg loss: 0.0288\n",
      "Validation Results - Epoch: 18  Avg accuracy: 0.76 Avg loss: 0.7323\n",
      "Training Results - Avg loss: 0.0162\n",
      "Training Results - Avg loss: 0.0373\n",
      "Training Results - Avg loss: 0.0444\n",
      "Training Results - Avg loss: 0.0328\n",
      "Training Results - Avg loss: 0.0407\n",
      "Training Results - Avg loss: 0.0212\n",
      "Training Results - Avg loss: 0.0287\n",
      "Training Results - Avg loss: 0.0173\n",
      "Training Results - Avg loss: 0.0189\n",
      "Training Results - Avg loss: 0.0248\n",
      "Training Results - Avg loss: 0.0246\n",
      "Training Results - Avg loss: 0.0337\n",
      "Training Results - Avg loss: 0.0267\n",
      "Training Results - Avg loss: 0.0242\n",
      "Training Results - Avg loss: 0.0315\n",
      "Training Results - Avg loss: 0.0305\n",
      "Training Results - Avg loss: 0.0221\n",
      "Training Results - Avg loss: 0.0447\n",
      "Training Results - Avg loss: 0.0517\n",
      "Training Results - Avg loss: 0.0191\n",
      "Training Results - Avg loss: 0.0197\n",
      "Training Results - Avg loss: 0.0177\n",
      "Training Results - Avg loss: 0.0151\n",
      "Training Results - Epoch: 19  Avg accuracy: 1.00 Avg loss: 0.0236\n",
      "Validation Results - Epoch: 19  Avg accuracy: 0.77 Avg loss: 0.7775\n",
      "Training Results - Avg loss: 0.0237\n",
      "Training Results - Avg loss: 0.0289\n",
      "Training Results - Avg loss: 0.0107\n",
      "Training Results - Avg loss: 0.0290\n",
      "Training Results - Avg loss: 0.0321\n",
      "Training Results - Avg loss: 0.0249\n",
      "Training Results - Avg loss: 0.0299\n",
      "Training Results - Avg loss: 0.0230\n",
      "Training Results - Avg loss: 0.0192\n",
      "Training Results - Avg loss: 0.0201\n",
      "Training Results - Avg loss: 0.0336\n",
      "Training Results - Avg loss: 0.0198\n",
      "Training Results - Avg loss: 0.0142\n",
      "Training Results - Avg loss: 0.0331\n",
      "Training Results - Avg loss: 0.0205\n",
      "Training Results - Avg loss: 0.0238\n",
      "Training Results - Avg loss: 0.0277\n",
      "Training Results - Avg loss: 0.0283\n",
      "Training Results - Avg loss: 0.0182\n",
      "Training Results - Avg loss: 0.0158\n",
      "Training Results - Avg loss: 0.0198\n",
      "Training Results - Avg loss: 0.0164\n",
      "Training Results - Avg loss: 0.0368\n",
      "Training Results - Epoch: 20  Avg accuracy: 1.00 Avg loss: 0.0152\n",
      "Validation Results - Epoch: 20  Avg accuracy: 0.77 Avg loss: 0.7667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▃▄▅▅▆▇▇▇▇█████████</td></tr><tr><td>train_loss</td><td>████████▇▆▆▆▆▅▅▅▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▆▆▆▇▇█▇▇█████▇█▇</td></tr><tr><td>val_loss</td><td>▆▆▅▄▂▂▁▁▁▁▁▂▂▃▃▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.99861</td></tr><tr><td>train_loss</td><td>0.01516</td></tr><tr><td>val_accuracy</td><td>0.7656</td></tr><tr><td>val_loss</td><td>0.76665</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual-elevator-306</strong> at: <a href='https://wandb.ai/ts-robustness/ml-course/runs/qqtsxdyp' target=\"_blank\">https://wandb.ai/ts-robustness/ml-course/runs/qqtsxdyp</a><br/> View job at <a href='https://wandb.ai/ts-robustness/ml-course/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0ODA3MTk2NA==/version_details/v1' target=\"_blank\">https://wandb.ai/ts-robustness/ml-course/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0ODA3MTk2NA==/version_details/v1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240312_211437-qqtsxdyp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize your optimizer and criterion\n",
    "optimizer = build_optimizer(config, model)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = criterion(y_pred, y.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x)\n",
    "        return y_pred, y\n",
    "\n",
    "train_evaluator = Engine(validation_step)\n",
    "val_evaluator = Engine(validation_step)\n",
    "\n",
    "# Attach metrics to the evaluators\n",
    "metrics = {\n",
    "    'accuracy': Accuracy(output_transform=lambda x: (x[0] > 0.5, x[1])),\n",
    "    'loss': Loss(criterion, output_transform=lambda x: (x[0], x[1].unsqueeze(1)))\n",
    "}\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(val_evaluator, name)\n",
    "\n",
    "\n",
    "# checkpoint_handler = ModelCheckpoint(dirname='saved_models', filename_prefix='best',\n",
    "#                                      n_saved=1, require_empty=False,\n",
    "#                                      score_function=lambda engine: engine.state.metrics['accuracy'],\n",
    "#                                      score_name=\"accuracy\", global_step_transform=lambda *_: trainer.state.epoch)\n",
    "# val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler, {\"model\": model})\n",
    "\n",
    "\n",
    "### Logging\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(trainer):\n",
    "    batch_loss = trainer.state.output\n",
    "    print(\"Training Results - Avg loss: {:.4f}\".format(batch_loss))\n",
    "    wandb.log({\"train_loss\": batch_loss})\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_dataloader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.4f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['loss']))\n",
    "    wandb.log({\"train_accuracy\": metrics['accuracy'],\n",
    "               \"train_loss\": metrics['loss']})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_dataloader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.4f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['loss']))\n",
    "    wandb.log({\"val_accuracy\": metrics['accuracy'],\n",
    "               \"val_loss\": metrics['loss']})\n",
    "\n",
    "\n",
    "# Run the training loop\n",
    "trainer.run(train_dataloader, max_epochs=config['train']['n_epoch'])\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52137287-0730-4268-8eab-c06a29efb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../model/lstm_model.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
