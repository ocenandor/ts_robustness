{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from ignite.engine import (Engine, Events, create_supervised_evaluator,\n",
    "                           create_supervised_trainer)\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.datasets import FordDataset\n",
    "from src.models import TransformerClassification\n",
    "from src.utils import split_batch, build_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 50\n",
    "\n",
    "config = {\n",
    "    \"model\":{\n",
    "        \"encoder\": {\n",
    "            \"d_model\": n_splits,\n",
    "            \"nhead\": n_splits // 2,\n",
    "            \"layer_norm_eps\": 1e-3,\n",
    "            \"dropout\": 0.5\n",
    "        },\n",
    "        \"num_layers\": 2,\n",
    "        \"fc\":{\n",
    "            \"dim\": 50,\n",
    "            \"dropout\": 0.5\n",
    "        }\n",
    "    },\n",
    "    \"train\":{\n",
    "        \"optimizer\": torch.optim.Adam,\n",
    "        \"lr\": 3e-4,\n",
    "        \"n_epoch\": 30\n",
    "    },\n",
    "    \"random_state\": np.random.randint(0, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/FordA/FordA_TRAIN.arff\"\n",
    "test_path = \"../data/FordA/FordA_TEST.arff\"\n",
    "\n",
    "train_dataset = FordDataset(train_path)\n",
    "test_dataset = FordDataset(test_path)\n",
    "\n",
    "idx = np.arange(len(train_dataset))\n",
    "idx_train, idx_val = train_test_split(idx, train_size=0.8, stratify=train_dataset.labels, random_state=config['random_state'])\n",
    "\n",
    "train_sampler = SubsetRandomSampler(idx_train)\n",
    "val_sampler = SubsetRandomSampler(idx_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, sampler=train_sampler, collate_fn=partial(split_batch, n_splits=n_splits))\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=128, sampler=val_sampler, collate_fn=partial(split_batch, n_splits=n_splits))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, collate_fn=partial(split_batch, n_splits=n_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ptmeg\\OneDrive\\Документы\\Skoltech\\Term3\\ML\\ts_robustness\\notebooks\\wandb\\run-20240226_205323-jees2fse</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ts-robustness/ml-course/runs/jees2fse' target=\"_blank\">icy-leaf-50</a></strong> to <a href='https://wandb.ai/ts-robustness/ml-course' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ts-robustness/ml-course' target=\"_blank\">https://wandb.ai/ts-robustness/ml-course</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ts-robustness/ml-course/runs/jees2fse' target=\"_blank\">https://wandb.ai/ts-robustness/ml-course/runs/jees2fse</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Avg loss: 0.6989\n",
      "Training Results - Avg loss: 0.6869\n",
      "Training Results - Avg loss: 0.7095\n",
      "Training Results - Avg loss: 0.6974\n",
      "Training Results - Avg loss: 0.7173\n",
      "Training Results - Avg loss: 0.6907\n",
      "Training Results - Avg loss: 0.6811\n",
      "Training Results - Avg loss: 0.6987\n",
      "Training Results - Avg loss: 0.6845\n",
      "Training Results - Avg loss: 0.6907\n",
      "Training Results - Avg loss: 0.6923\n",
      "Training Results - Avg loss: 0.6826\n",
      "Training Results - Avg loss: 0.6868\n",
      "Training Results - Avg loss: 0.6806\n",
      "Training Results - Avg loss: 0.6796\n",
      "Training Results - Avg loss: 0.6654\n",
      "Training Results - Avg loss: 0.6801\n",
      "Training Results - Avg loss: 0.6739\n",
      "Training Results - Avg loss: 0.7172\n",
      "Training Results - Avg loss: 0.7069\n",
      "Training Results - Avg loss: 0.6621\n",
      "Training Results - Avg loss: 0.6704\n",
      "Training Results - Avg loss: 0.7022\n",
      "Training Results - Epoch: 1  Avg accuracy: 0.66 Avg loss: 0.6540\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.61 Avg loss: 0.6661\n",
      "Training Results - Avg loss: 0.6670\n",
      "Training Results - Avg loss: 0.6853\n",
      "Training Results - Avg loss: 0.6669\n",
      "Training Results - Avg loss: 0.6582\n",
      "Training Results - Avg loss: 0.6607\n",
      "Training Results - Avg loss: 0.6610\n",
      "Training Results - Avg loss: 0.6804\n",
      "Training Results - Avg loss: 0.6800\n",
      "Training Results - Avg loss: 0.6457\n",
      "Training Results - Avg loss: 0.6602\n",
      "Training Results - Avg loss: 0.6554\n",
      "Training Results - Avg loss: 0.6516\n",
      "Training Results - Avg loss: 0.6605\n",
      "Training Results - Avg loss: 0.6653\n",
      "Training Results - Avg loss: 0.6343\n",
      "Training Results - Avg loss: 0.6886\n",
      "Training Results - Avg loss: 0.6626\n",
      "Training Results - Avg loss: 0.6674\n",
      "Training Results - Avg loss: 0.6508\n",
      "Training Results - Avg loss: 0.6458\n",
      "Training Results - Avg loss: 0.6554\n",
      "Training Results - Avg loss: 0.6566\n",
      "Training Results - Avg loss: 0.6432\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.72 Avg loss: 0.6093\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.69 Avg loss: 0.6322\n",
      "Training Results - Avg loss: 0.6407\n",
      "Training Results - Avg loss: 0.6095\n",
      "Training Results - Avg loss: 0.6405\n",
      "Training Results - Avg loss: 0.6401\n",
      "Training Results - Avg loss: 0.6050\n",
      "Training Results - Avg loss: 0.6331\n",
      "Training Results - Avg loss: 0.6192\n",
      "Training Results - Avg loss: 0.6479\n",
      "Training Results - Avg loss: 0.6277\n",
      "Training Results - Avg loss: 0.6133\n",
      "Training Results - Avg loss: 0.6345\n",
      "Training Results - Avg loss: 0.6011\n",
      "Training Results - Avg loss: 0.6002\n",
      "Training Results - Avg loss: 0.6395\n",
      "Training Results - Avg loss: 0.6184\n",
      "Training Results - Avg loss: 0.6041\n",
      "Training Results - Avg loss: 0.6019\n",
      "Training Results - Avg loss: 0.5897\n",
      "Training Results - Avg loss: 0.6007\n",
      "Training Results - Avg loss: 0.6277\n",
      "Training Results - Avg loss: 0.6293\n",
      "Training Results - Avg loss: 0.5803\n",
      "Training Results - Avg loss: 0.5486\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.75 Avg loss: 0.5572\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.71 Avg loss: 0.5972\n",
      "Training Results - Avg loss: 0.5939\n",
      "Training Results - Avg loss: 0.5919\n",
      "Training Results - Avg loss: 0.5747\n",
      "Training Results - Avg loss: 0.5722\n",
      "Training Results - Avg loss: 0.5830\n",
      "Training Results - Avg loss: 0.5805\n",
      "Training Results - Avg loss: 0.6081\n",
      "Training Results - Avg loss: 0.5957\n",
      "Training Results - Avg loss: 0.5483\n",
      "Training Results - Avg loss: 0.5974\n",
      "Training Results - Avg loss: 0.5747\n",
      "Training Results - Avg loss: 0.5252\n",
      "Training Results - Avg loss: 0.5727\n",
      "Training Results - Avg loss: 0.5930\n",
      "Training Results - Avg loss: 0.5485\n",
      "Training Results - Avg loss: 0.6038\n",
      "Training Results - Avg loss: 0.5643\n",
      "Training Results - Avg loss: 0.5249\n",
      "Training Results - Avg loss: 0.4869\n",
      "Training Results - Avg loss: 0.5343\n",
      "Training Results - Avg loss: 0.5441\n",
      "Training Results - Avg loss: 0.5532\n",
      "Training Results - Avg loss: 0.5905\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.78 Avg loss: 0.4891\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.75 Avg loss: 0.5482\n",
      "Training Results - Avg loss: 0.5484\n",
      "Training Results - Avg loss: 0.5285\n",
      "Training Results - Avg loss: 0.5264\n",
      "Training Results - Avg loss: 0.5147\n",
      "Training Results - Avg loss: 0.4992\n",
      "Training Results - Avg loss: 0.5274\n",
      "Training Results - Avg loss: 0.5173\n",
      "Training Results - Avg loss: 0.4910\n",
      "Training Results - Avg loss: 0.5068\n",
      "Training Results - Avg loss: 0.5939\n",
      "Training Results - Avg loss: 0.5650\n",
      "Training Results - Avg loss: 0.4849\n",
      "Training Results - Avg loss: 0.4191\n",
      "Training Results - Avg loss: 0.5054\n",
      "Training Results - Avg loss: 0.5334\n",
      "Training Results - Avg loss: 0.5370\n",
      "Training Results - Avg loss: 0.4763\n",
      "Training Results - Avg loss: 0.5203\n",
      "Training Results - Avg loss: 0.5541\n",
      "Training Results - Avg loss: 0.5082\n",
      "Training Results - Avg loss: 0.4926\n",
      "Training Results - Avg loss: 0.4760\n",
      "Training Results - Avg loss: 0.5683\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.80 Avg loss: 0.4517\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.75 Avg loss: 0.5300\n",
      "Training Results - Avg loss: 0.4891\n",
      "Training Results - Avg loss: 0.4274\n",
      "Training Results - Avg loss: 0.4360\n",
      "Training Results - Avg loss: 0.4331\n",
      "Training Results - Avg loss: 0.5709\n",
      "Training Results - Avg loss: 0.4423\n",
      "Training Results - Avg loss: 0.4963\n",
      "Training Results - Avg loss: 0.4925\n",
      "Training Results - Avg loss: 0.4823\n",
      "Training Results - Avg loss: 0.4878\n",
      "Training Results - Avg loss: 0.4966\n",
      "Training Results - Avg loss: 0.4576\n",
      "Training Results - Avg loss: 0.5148\n",
      "Training Results - Avg loss: 0.4464\n",
      "Training Results - Avg loss: 0.4541\n",
      "Training Results - Avg loss: 0.5190\n",
      "Training Results - Avg loss: 0.4587\n",
      "Training Results - Avg loss: 0.3827\n",
      "Training Results - Avg loss: 0.5049\n",
      "Training Results - Avg loss: 0.4511\n",
      "Training Results - Avg loss: 0.3554\n",
      "Training Results - Avg loss: 0.4870\n",
      "Training Results - Avg loss: 0.6067\n",
      "Training Results - Epoch: 6  Avg accuracy: 0.84 Avg loss: 0.3963\n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.79 Avg loss: 0.4972\n",
      "Training Results - Avg loss: 0.3940\n",
      "Training Results - Avg loss: 0.4368\n",
      "Training Results - Avg loss: 0.3786\n",
      "Training Results - Avg loss: 0.4262\n",
      "Training Results - Avg loss: 0.4547\n",
      "Training Results - Avg loss: 0.4422\n",
      "Training Results - Avg loss: 0.4446\n",
      "Training Results - Avg loss: 0.4795\n",
      "Training Results - Avg loss: 0.4318\n",
      "Training Results - Avg loss: 0.4835\n",
      "Training Results - Avg loss: 0.4740\n",
      "Training Results - Avg loss: 0.4355\n",
      "Training Results - Avg loss: 0.4630\n",
      "Training Results - Avg loss: 0.4037\n",
      "Training Results - Avg loss: 0.4478\n",
      "Training Results - Avg loss: 0.3991\n",
      "Training Results - Avg loss: 0.3822\n",
      "Training Results - Avg loss: 0.4549\n",
      "Training Results - Avg loss: 0.5116\n",
      "Training Results - Avg loss: 0.4478\n",
      "Training Results - Avg loss: 0.3672\n",
      "Training Results - Avg loss: 0.3406\n",
      "Training Results - Avg loss: 0.3857\n",
      "Training Results - Epoch: 7  Avg accuracy: 0.86 Avg loss: 0.3544\n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.82 Avg loss: 0.4840\n",
      "Training Results - Avg loss: 0.3994\n",
      "Training Results - Avg loss: 0.3606\n",
      "Training Results - Avg loss: 0.3831\n",
      "Training Results - Avg loss: 0.4012\n",
      "Training Results - Avg loss: 0.4479\n",
      "Training Results - Avg loss: 0.4189\n",
      "Training Results - Avg loss: 0.3974\n",
      "Training Results - Avg loss: 0.3723\n",
      "Training Results - Avg loss: 0.3139\n",
      "Training Results - Avg loss: 0.4245\n",
      "Training Results - Avg loss: 0.3206\n",
      "Training Results - Avg loss: 0.3825\n",
      "Training Results - Avg loss: 0.3702\n",
      "Training Results - Avg loss: 0.3424\n",
      "Training Results - Avg loss: 0.4451\n",
      "Training Results - Avg loss: 0.3421\n",
      "Training Results - Avg loss: 0.3896\n",
      "Training Results - Avg loss: 0.3672\n",
      "Training Results - Avg loss: 0.3638\n",
      "Training Results - Avg loss: 0.3218\n",
      "Training Results - Avg loss: 0.3898\n",
      "Training Results - Avg loss: 0.3972\n",
      "Training Results - Avg loss: 0.4393\n",
      "Training Results - Epoch: 8  Avg accuracy: 0.87 Avg loss: 0.3237\n",
      "Validation Results - Epoch: 8  Avg accuracy: 0.82 Avg loss: 0.4576\n",
      "Training Results - Avg loss: 0.3075\n",
      "Training Results - Avg loss: 0.4073\n",
      "Training Results - Avg loss: 0.3937\n",
      "Training Results - Avg loss: 0.2975\n",
      "Training Results - Avg loss: 0.3005\n",
      "Training Results - Avg loss: 0.4103\n",
      "Training Results - Avg loss: 0.3558\n",
      "Training Results - Avg loss: 0.4147\n",
      "Training Results - Avg loss: 0.4109\n",
      "Training Results - Avg loss: 0.2997\n",
      "Training Results - Avg loss: 0.2974\n",
      "Training Results - Avg loss: 0.4618\n",
      "Training Results - Avg loss: 0.3738\n",
      "Training Results - Avg loss: 0.3235\n",
      "Training Results - Avg loss: 0.3545\n",
      "Training Results - Avg loss: 0.4125\n",
      "Training Results - Avg loss: 0.4530\n",
      "Training Results - Avg loss: 0.2910\n",
      "Training Results - Avg loss: 0.3901\n",
      "Training Results - Avg loss: 0.4434\n",
      "Training Results - Avg loss: 0.3617\n",
      "Training Results - Avg loss: 0.3067\n",
      "Training Results - Avg loss: 0.2546\n",
      "Training Results - Epoch: 9  Avg accuracy: 0.88 Avg loss: 0.3271\n",
      "Validation Results - Epoch: 9  Avg accuracy: 0.81 Avg loss: 0.5047\n",
      "Training Results - Avg loss: 0.4185\n",
      "Training Results - Avg loss: 0.3694\n",
      "Training Results - Avg loss: 0.3525\n",
      "Training Results - Avg loss: 0.3610\n",
      "Training Results - Avg loss: 0.2983\n",
      "Training Results - Avg loss: 0.3849\n",
      "Training Results - Avg loss: 0.3141\n",
      "Training Results - Avg loss: 0.3145\n",
      "Training Results - Avg loss: 0.3493\n",
      "Training Results - Avg loss: 0.3706\n",
      "Training Results - Avg loss: 0.4580\n",
      "Training Results - Avg loss: 0.3265\n",
      "Training Results - Avg loss: 0.2872\n",
      "Training Results - Avg loss: 0.4396\n",
      "Training Results - Avg loss: 0.3897\n",
      "Training Results - Avg loss: 0.3132\n",
      "Training Results - Avg loss: 0.3306\n",
      "Training Results - Avg loss: 0.3135\n",
      "Training Results - Avg loss: 0.3269\n",
      "Training Results - Avg loss: 0.2918\n",
      "Training Results - Avg loss: 0.2760\n",
      "Training Results - Avg loss: 0.3260\n",
      "Training Results - Avg loss: 0.4619\n",
      "Training Results - Epoch: 10  Avg accuracy: 0.89 Avg loss: 0.2777\n",
      "Validation Results - Epoch: 10  Avg accuracy: 0.82 Avg loss: 0.4787\n",
      "Training Results - Avg loss: 0.3319\n",
      "Training Results - Avg loss: 0.3461\n",
      "Training Results - Avg loss: 0.3957\n",
      "Training Results - Avg loss: 0.2796\n",
      "Training Results - Avg loss: 0.3323\n",
      "Training Results - Avg loss: 0.3068\n",
      "Training Results - Avg loss: 0.3017\n",
      "Training Results - Avg loss: 0.2936\n",
      "Training Results - Avg loss: 0.2384\n",
      "Training Results - Avg loss: 0.3326\n",
      "Training Results - Avg loss: 0.3485\n",
      "Training Results - Avg loss: 0.2649\n",
      "Training Results - Avg loss: 0.4297\n",
      "Training Results - Avg loss: 0.2971\n",
      "Training Results - Avg loss: 0.2520\n",
      "Training Results - Avg loss: 0.3131\n",
      "Training Results - Avg loss: 0.4008\n",
      "Training Results - Avg loss: 0.3260\n",
      "Training Results - Avg loss: 0.3331\n",
      "Training Results - Avg loss: 0.2574\n",
      "Training Results - Avg loss: 0.3441\n",
      "Training Results - Avg loss: 0.2709\n",
      "Training Results - Avg loss: 0.3455\n",
      "Training Results - Epoch: 11  Avg accuracy: 0.88 Avg loss: 0.2917\n",
      "Validation Results - Epoch: 11  Avg accuracy: 0.83 Avg loss: 0.4855\n",
      "Training Results - Avg loss: 0.4030\n",
      "Training Results - Avg loss: 0.3806\n",
      "Training Results - Avg loss: 0.2410\n",
      "Training Results - Avg loss: 0.3413\n",
      "Training Results - Avg loss: 0.3465\n",
      "Training Results - Avg loss: 0.2075\n",
      "Training Results - Avg loss: 0.3873\n",
      "Training Results - Avg loss: 0.3033\n",
      "Training Results - Avg loss: 0.4038\n",
      "Training Results - Avg loss: 0.3561\n",
      "Training Results - Avg loss: 0.3028\n",
      "Training Results - Avg loss: 0.2945\n",
      "Training Results - Avg loss: 0.3420\n",
      "Training Results - Avg loss: 0.3362\n",
      "Training Results - Avg loss: 0.3680\n",
      "Training Results - Avg loss: 0.3278\n",
      "Training Results - Avg loss: 0.3807\n",
      "Training Results - Avg loss: 0.3871\n",
      "Training Results - Avg loss: 0.3730\n",
      "Training Results - Avg loss: 0.2885\n",
      "Training Results - Avg loss: 0.3474\n",
      "Training Results - Avg loss: 0.2692\n",
      "Training Results - Avg loss: 0.2842\n",
      "Training Results - Epoch: 12  Avg accuracy: 0.91 Avg loss: 0.2415\n",
      "Validation Results - Epoch: 12  Avg accuracy: 0.83 Avg loss: 0.4606\n",
      "Training Results - Avg loss: 0.3285\n",
      "Training Results - Avg loss: 0.2455\n",
      "Training Results - Avg loss: 0.4133\n",
      "Training Results - Avg loss: 0.2272\n",
      "Training Results - Avg loss: 0.3541\n",
      "Training Results - Avg loss: 0.3271\n",
      "Training Results - Avg loss: 0.2271\n",
      "Training Results - Avg loss: 0.2449\n",
      "Training Results - Avg loss: 0.2505\n",
      "Training Results - Avg loss: 0.3177\n",
      "Training Results - Avg loss: 0.3041\n",
      "Training Results - Avg loss: 0.2915\n",
      "Training Results - Avg loss: 0.2535\n",
      "Training Results - Avg loss: 0.2460\n",
      "Training Results - Avg loss: 0.2113\n",
      "Training Results - Avg loss: 0.2649\n",
      "Training Results - Avg loss: 0.3263\n",
      "Training Results - Avg loss: 0.3007\n",
      "Training Results - Avg loss: 0.2067\n",
      "Training Results - Avg loss: 0.2298\n",
      "Training Results - Avg loss: 0.3242\n",
      "Training Results - Avg loss: 0.3622\n",
      "Training Results - Avg loss: 0.1520\n",
      "Training Results - Epoch: 13  Avg accuracy: 0.91 Avg loss: 0.2327\n",
      "Validation Results - Epoch: 13  Avg accuracy: 0.84 Avg loss: 0.4664\n",
      "Training Results - Avg loss: 0.2573\n",
      "Training Results - Avg loss: 0.3252\n",
      "Training Results - Avg loss: 0.2800\n",
      "Training Results - Avg loss: 0.3153\n",
      "Training Results - Avg loss: 0.2321\n",
      "Training Results - Avg loss: 0.2769\n",
      "Training Results - Avg loss: 0.3383\n",
      "Training Results - Avg loss: 0.4725\n",
      "Training Results - Avg loss: 0.3117\n",
      "Training Results - Avg loss: 0.2034\n",
      "Training Results - Avg loss: 0.3161\n",
      "Training Results - Avg loss: 0.2831\n",
      "Training Results - Avg loss: 0.2354\n",
      "Training Results - Avg loss: 0.3193\n",
      "Training Results - Avg loss: 0.2548\n",
      "Training Results - Avg loss: 0.2694\n",
      "Training Results - Avg loss: 0.2149\n",
      "Training Results - Avg loss: 0.2375\n",
      "Training Results - Avg loss: 0.2892\n",
      "Training Results - Avg loss: 0.2072\n",
      "Training Results - Avg loss: 0.2765\n",
      "Training Results - Avg loss: 0.3191\n",
      "Training Results - Avg loss: 0.2364\n",
      "Training Results - Epoch: 14  Avg accuracy: 0.92 Avg loss: 0.2215\n",
      "Validation Results - Epoch: 14  Avg accuracy: 0.84 Avg loss: 0.4636\n",
      "Training Results - Avg loss: 0.2903\n",
      "Training Results - Avg loss: 0.2008\n",
      "Training Results - Avg loss: 0.2405\n",
      "Training Results - Avg loss: 0.2254\n",
      "Training Results - Avg loss: 0.2837\n",
      "Training Results - Avg loss: 0.1553\n",
      "Training Results - Avg loss: 0.2929\n",
      "Training Results - Avg loss: 0.2266\n",
      "Training Results - Avg loss: 0.2187\n",
      "Training Results - Avg loss: 0.3209\n",
      "Training Results - Avg loss: 0.3596\n",
      "Training Results - Avg loss: 0.3497\n",
      "Training Results - Avg loss: 0.3663\n",
      "Training Results - Avg loss: 0.2210\n",
      "Training Results - Avg loss: 0.2497\n",
      "Training Results - Avg loss: 0.2124\n",
      "Training Results - Avg loss: 0.2486\n",
      "Training Results - Avg loss: 0.3602\n",
      "Training Results - Avg loss: 0.3327\n",
      "Training Results - Avg loss: 0.2311\n",
      "Training Results - Avg loss: 0.2468\n",
      "Training Results - Avg loss: 0.3309\n",
      "Training Results - Avg loss: 0.1632\n",
      "Training Results - Epoch: 15  Avg accuracy: 0.91 Avg loss: 0.2181\n",
      "Validation Results - Epoch: 15  Avg accuracy: 0.83 Avg loss: 0.4575\n",
      "Training Results - Avg loss: 0.3455\n",
      "Training Results - Avg loss: 0.1686\n",
      "Training Results - Avg loss: 0.2188\n",
      "Training Results - Avg loss: 0.2662\n",
      "Training Results - Avg loss: 0.2708\n",
      "Training Results - Avg loss: 0.3746\n",
      "Training Results - Avg loss: 0.2364\n",
      "Training Results - Avg loss: 0.2928\n",
      "Training Results - Avg loss: 0.2762\n",
      "Training Results - Avg loss: 0.2675\n",
      "Training Results - Avg loss: 0.3321\n",
      "Training Results - Avg loss: 0.1558\n",
      "Training Results - Avg loss: 0.2045\n",
      "Training Results - Avg loss: 0.3327\n",
      "Training Results - Avg loss: 0.3994\n",
      "Training Results - Avg loss: 0.2376\n",
      "Training Results - Avg loss: 0.3057\n",
      "Training Results - Avg loss: 0.2616\n",
      "Training Results - Avg loss: 0.2297\n",
      "Training Results - Avg loss: 0.2370\n",
      "Training Results - Avg loss: 0.2684\n",
      "Training Results - Avg loss: 0.2414\n",
      "Training Results - Avg loss: 0.2883\n",
      "Training Results - Epoch: 16  Avg accuracy: 0.92 Avg loss: 0.2063\n",
      "Validation Results - Epoch: 16  Avg accuracy: 0.84 Avg loss: 0.4598\n",
      "Training Results - Avg loss: 0.2522\n",
      "Training Results - Avg loss: 0.1944\n",
      "Training Results - Avg loss: 0.3129\n",
      "Training Results - Avg loss: 0.2593\n",
      "Training Results - Avg loss: 0.2327\n",
      "Training Results - Avg loss: 0.2418\n",
      "Training Results - Avg loss: 0.2893\n",
      "Training Results - Avg loss: 0.2969\n",
      "Training Results - Avg loss: 0.3290\n",
      "Training Results - Avg loss: 0.3091\n",
      "Training Results - Avg loss: 0.1962\n",
      "Training Results - Avg loss: 0.3113\n",
      "Training Results - Avg loss: 0.2651\n",
      "Training Results - Avg loss: 0.1679\n",
      "Training Results - Avg loss: 0.2870\n",
      "Training Results - Avg loss: 0.2641\n",
      "Training Results - Avg loss: 0.3147\n",
      "Training Results - Avg loss: 0.2373\n",
      "Training Results - Avg loss: 0.2567\n",
      "Training Results - Avg loss: 0.1876\n",
      "Training Results - Avg loss: 0.3577\n",
      "Training Results - Avg loss: 0.3159\n",
      "Training Results - Avg loss: 0.2543\n",
      "Training Results - Epoch: 17  Avg accuracy: 0.92 Avg loss: 0.2027\n",
      "Validation Results - Epoch: 17  Avg accuracy: 0.83 Avg loss: 0.4719\n",
      "Training Results - Avg loss: 0.2825\n",
      "Training Results - Avg loss: 0.2139\n",
      "Training Results - Avg loss: 0.2502\n",
      "Training Results - Avg loss: 0.2153\n",
      "Training Results - Avg loss: 0.2053\n",
      "Training Results - Avg loss: 0.2249\n",
      "Training Results - Avg loss: 0.2221\n",
      "Training Results - Avg loss: 0.2192\n",
      "Training Results - Avg loss: 0.1951\n",
      "Training Results - Avg loss: 0.2381\n",
      "Training Results - Avg loss: 0.2242\n",
      "Training Results - Avg loss: 0.2548\n",
      "Training Results - Avg loss: 0.2956\n",
      "Training Results - Avg loss: 0.1767\n",
      "Training Results - Avg loss: 0.2413\n",
      "Training Results - Avg loss: 0.2073\n",
      "Training Results - Avg loss: 0.2720\n",
      "Training Results - Avg loss: 0.2433\n",
      "Training Results - Avg loss: 0.3237\n",
      "Training Results - Avg loss: 0.2805\n",
      "Training Results - Avg loss: 0.2626\n",
      "Training Results - Avg loss: 0.3249\n",
      "Training Results - Avg loss: 0.4133\n",
      "Training Results - Epoch: 18  Avg accuracy: 0.93 Avg loss: 0.1941\n",
      "Validation Results - Epoch: 18  Avg accuracy: 0.83 Avg loss: 0.5078\n",
      "Training Results - Avg loss: 0.2576\n",
      "Training Results - Avg loss: 0.2583\n",
      "Training Results - Avg loss: 0.2789\n",
      "Training Results - Avg loss: 0.2598\n",
      "Training Results - Avg loss: 0.2513\n",
      "Training Results - Avg loss: 0.1709\n",
      "Training Results - Avg loss: 0.2322\n",
      "Training Results - Avg loss: 0.1858\n",
      "Training Results - Avg loss: 0.2503\n",
      "Training Results - Avg loss: 0.2688\n",
      "Training Results - Avg loss: 0.2384\n",
      "Training Results - Avg loss: 0.2352\n",
      "Training Results - Avg loss: 0.2067\n",
      "Training Results - Avg loss: 0.3129\n",
      "Training Results - Avg loss: 0.2202\n",
      "Training Results - Avg loss: 0.1608\n",
      "Training Results - Avg loss: 0.2614\n",
      "Training Results - Avg loss: 0.2589\n",
      "Training Results - Avg loss: 0.2727\n",
      "Training Results - Avg loss: 0.1990\n",
      "Training Results - Avg loss: 0.2427\n",
      "Training Results - Avg loss: 0.1804\n",
      "Training Results - Avg loss: 0.1906\n",
      "Training Results - Epoch: 19  Avg accuracy: 0.93 Avg loss: 0.1715\n",
      "Validation Results - Epoch: 19  Avg accuracy: 0.83 Avg loss: 0.5039\n",
      "Training Results - Avg loss: 0.1509\n",
      "Training Results - Avg loss: 0.2531\n",
      "Training Results - Avg loss: 0.1884\n",
      "Training Results - Avg loss: 0.1225\n",
      "Training Results - Avg loss: 0.2756\n",
      "Training Results - Avg loss: 0.2842\n",
      "Training Results - Avg loss: 0.2504\n",
      "Training Results - Avg loss: 0.2680\n",
      "Training Results - Avg loss: 0.1918\n",
      "Training Results - Avg loss: 0.1353\n",
      "Training Results - Avg loss: 0.2783\n",
      "Training Results - Avg loss: 0.2897\n",
      "Training Results - Avg loss: 0.2434\n",
      "Training Results - Avg loss: 0.1952\n",
      "Training Results - Avg loss: 0.2444\n",
      "Training Results - Avg loss: 0.2164\n",
      "Training Results - Avg loss: 0.2143\n",
      "Training Results - Avg loss: 0.2326\n",
      "Training Results - Avg loss: 0.2268\n",
      "Training Results - Avg loss: 0.1634\n",
      "Training Results - Avg loss: 0.3274\n",
      "Training Results - Avg loss: 0.2373\n",
      "Training Results - Avg loss: 0.2389\n",
      "Training Results - Epoch: 20  Avg accuracy: 0.93 Avg loss: 0.1783\n",
      "Validation Results - Epoch: 20  Avg accuracy: 0.84 Avg loss: 0.4972\n",
      "Training Results - Avg loss: 0.1926\n",
      "Training Results - Avg loss: 0.2300\n",
      "Training Results - Avg loss: 0.2357\n",
      "Training Results - Avg loss: 0.3264\n",
      "Training Results - Avg loss: 0.1570\n",
      "Training Results - Avg loss: 0.1859\n",
      "Training Results - Avg loss: 0.1769\n",
      "Training Results - Avg loss: 0.2865\n",
      "Training Results - Avg loss: 0.2307\n",
      "Training Results - Avg loss: 0.2116\n",
      "Training Results - Avg loss: 0.1386\n",
      "Training Results - Avg loss: 0.2296\n",
      "Training Results - Avg loss: 0.2511\n",
      "Training Results - Avg loss: 0.1985\n",
      "Training Results - Avg loss: 0.2515\n",
      "Training Results - Avg loss: 0.2512\n",
      "Training Results - Avg loss: 0.2230\n",
      "Training Results - Avg loss: 0.2619\n",
      "Training Results - Avg loss: 0.2306\n",
      "Training Results - Avg loss: 0.1774\n",
      "Training Results - Avg loss: 0.1901\n",
      "Training Results - Avg loss: 0.2085\n",
      "Training Results - Avg loss: 0.1729\n",
      "Training Results - Epoch: 21  Avg accuracy: 0.93 Avg loss: 0.1786\n",
      "Validation Results - Epoch: 21  Avg accuracy: 0.84 Avg loss: 0.5211\n",
      "Training Results - Avg loss: 0.2036\n",
      "Training Results - Avg loss: 0.2363\n",
      "Training Results - Avg loss: 0.2600\n",
      "Training Results - Avg loss: 0.2103\n",
      "Training Results - Avg loss: 0.2033\n",
      "Training Results - Avg loss: 0.1793\n",
      "Training Results - Avg loss: 0.1860\n",
      "Training Results - Avg loss: 0.1602\n",
      "Training Results - Avg loss: 0.1832\n",
      "Training Results - Avg loss: 0.3748\n",
      "Training Results - Avg loss: 0.2731\n",
      "Training Results - Avg loss: 0.2278\n",
      "Training Results - Avg loss: 0.1997\n",
      "Training Results - Avg loss: 0.2175\n",
      "Training Results - Avg loss: 0.3289\n",
      "Training Results - Avg loss: 0.1721\n",
      "Training Results - Avg loss: 0.2175\n",
      "Training Results - Avg loss: 0.2120\n",
      "Training Results - Avg loss: 0.2087\n",
      "Training Results - Avg loss: 0.2659\n",
      "Training Results - Avg loss: 0.2186\n",
      "Training Results - Avg loss: 0.2426\n",
      "Training Results - Avg loss: 0.5148\n",
      "Training Results - Epoch: 22  Avg accuracy: 0.94 Avg loss: 0.1597\n",
      "Validation Results - Epoch: 22  Avg accuracy: 0.84 Avg loss: 0.5040\n",
      "Training Results - Avg loss: 0.1663\n",
      "Training Results - Avg loss: 0.1797\n",
      "Training Results - Avg loss: 0.1974\n",
      "Training Results - Avg loss: 0.2304\n",
      "Training Results - Avg loss: 0.1932\n",
      "Training Results - Avg loss: 0.2071\n",
      "Training Results - Avg loss: 0.2150\n",
      "Training Results - Avg loss: 0.1283\n",
      "Training Results - Avg loss: 0.1965\n",
      "Training Results - Avg loss: 0.1980\n",
      "Training Results - Avg loss: 0.2116\n",
      "Training Results - Avg loss: 0.2219\n",
      "Training Results - Avg loss: 0.2160\n",
      "Training Results - Avg loss: 0.2743\n",
      "Training Results - Avg loss: 0.1963\n",
      "Training Results - Avg loss: 0.2112\n",
      "Training Results - Avg loss: 0.2214\n",
      "Training Results - Avg loss: 0.1768\n",
      "Training Results - Avg loss: 0.2024\n",
      "Training Results - Avg loss: 0.3289\n",
      "Training Results - Avg loss: 0.2094\n",
      "Training Results - Avg loss: 0.2690\n",
      "Training Results - Avg loss: 0.1067\n",
      "Training Results - Epoch: 23  Avg accuracy: 0.94 Avg loss: 0.1595\n",
      "Validation Results - Epoch: 23  Avg accuracy: 0.83 Avg loss: 0.5163\n",
      "Training Results - Avg loss: 0.2927\n",
      "Training Results - Avg loss: 0.1568\n",
      "Training Results - Avg loss: 0.2350\n",
      "Training Results - Avg loss: 0.2667\n",
      "Training Results - Avg loss: 0.2271\n",
      "Training Results - Avg loss: 0.1440\n",
      "Training Results - Avg loss: 0.2351\n",
      "Training Results - Avg loss: 0.2137\n",
      "Training Results - Avg loss: 0.2157\n",
      "Training Results - Avg loss: 0.2287\n",
      "Training Results - Avg loss: 0.1853\n",
      "Training Results - Avg loss: 0.2146\n",
      "Training Results - Avg loss: 0.1763\n",
      "Training Results - Avg loss: 0.2873\n",
      "Training Results - Avg loss: 0.1231\n",
      "Training Results - Avg loss: 0.2076\n",
      "Training Results - Avg loss: 0.2189\n",
      "Training Results - Avg loss: 0.1556\n",
      "Training Results - Avg loss: 0.1701\n",
      "Training Results - Avg loss: 0.3067\n",
      "Training Results - Avg loss: 0.2056\n",
      "Training Results - Avg loss: 0.1861\n",
      "Training Results - Avg loss: 0.2389\n",
      "Training Results - Epoch: 24  Avg accuracy: 0.94 Avg loss: 0.1683\n",
      "Validation Results - Epoch: 24  Avg accuracy: 0.84 Avg loss: 0.5161\n",
      "Training Results - Avg loss: 0.2073\n",
      "Training Results - Avg loss: 0.2098\n",
      "Training Results - Avg loss: 0.2247\n",
      "Training Results - Avg loss: 0.2913\n",
      "Training Results - Avg loss: 0.1963\n",
      "Training Results - Avg loss: 0.2835\n",
      "Training Results - Avg loss: 0.1932\n",
      "Training Results - Avg loss: 0.2193\n",
      "Training Results - Avg loss: 0.1559\n",
      "Training Results - Avg loss: 0.2687\n",
      "Training Results - Avg loss: 0.2553\n",
      "Training Results - Avg loss: 0.1596\n",
      "Training Results - Avg loss: 0.1845\n",
      "Training Results - Avg loss: 0.1990\n",
      "Training Results - Avg loss: 0.2180\n",
      "Training Results - Avg loss: 0.2459\n",
      "Training Results - Avg loss: 0.2232\n",
      "Training Results - Avg loss: 0.1759\n",
      "Training Results - Avg loss: 0.3099\n",
      "Training Results - Avg loss: 0.1399\n",
      "Training Results - Avg loss: 0.2398\n",
      "Training Results - Avg loss: 0.2413\n",
      "Training Results - Avg loss: 0.2334\n",
      "Training Results - Epoch: 25  Avg accuracy: 0.95 Avg loss: 0.1344\n",
      "Validation Results - Epoch: 25  Avg accuracy: 0.84 Avg loss: 0.4939\n",
      "Training Results - Avg loss: 0.2095\n",
      "Training Results - Avg loss: 0.1593\n",
      "Training Results - Avg loss: 0.1841\n",
      "Training Results - Avg loss: 0.3400\n",
      "Training Results - Avg loss: 0.1515\n",
      "Training Results - Avg loss: 0.1733\n",
      "Training Results - Avg loss: 0.2010\n",
      "Training Results - Avg loss: 0.1299\n",
      "Training Results - Avg loss: 0.2268\n",
      "Training Results - Avg loss: 0.2869\n",
      "Training Results - Avg loss: 0.1915\n",
      "Training Results - Avg loss: 0.2148\n",
      "Training Results - Avg loss: 0.1313\n",
      "Training Results - Avg loss: 0.1376\n",
      "Training Results - Avg loss: 0.2008\n",
      "Training Results - Avg loss: 0.1712\n",
      "Training Results - Avg loss: 0.1828\n",
      "Training Results - Avg loss: 0.1780\n",
      "Training Results - Avg loss: 0.2487\n",
      "Training Results - Avg loss: 0.2215\n",
      "Training Results - Avg loss: 0.1704\n",
      "Training Results - Avg loss: 0.1693\n",
      "Training Results - Avg loss: 0.2980\n",
      "Training Results - Epoch: 26  Avg accuracy: 0.95 Avg loss: 0.1278\n",
      "Validation Results - Epoch: 26  Avg accuracy: 0.84 Avg loss: 0.5494\n",
      "Training Results - Avg loss: 0.1461\n",
      "Training Results - Avg loss: 0.1114\n",
      "Training Results - Avg loss: 0.1996\n",
      "Training Results - Avg loss: 0.1626\n",
      "Training Results - Avg loss: 0.2410\n",
      "Training Results - Avg loss: 0.1932\n",
      "Training Results - Avg loss: 0.1943\n",
      "Training Results - Avg loss: 0.2251\n",
      "Training Results - Avg loss: 0.1201\n",
      "Training Results - Avg loss: 0.2822\n",
      "Training Results - Avg loss: 0.1709\n",
      "Training Results - Avg loss: 0.1528\n",
      "Training Results - Avg loss: 0.1752\n",
      "Training Results - Avg loss: 0.1650\n",
      "Training Results - Avg loss: 0.2441\n",
      "Training Results - Avg loss: 0.1500\n",
      "Training Results - Avg loss: 0.1650\n",
      "Training Results - Avg loss: 0.2904\n",
      "Training Results - Avg loss: 0.1435\n",
      "Training Results - Avg loss: 0.1856\n",
      "Training Results - Avg loss: 0.2901\n",
      "Training Results - Avg loss: 0.1875\n",
      "Training Results - Avg loss: 0.1408\n",
      "Training Results - Epoch: 27  Avg accuracy: 0.94 Avg loss: 0.1522\n",
      "Validation Results - Epoch: 27  Avg accuracy: 0.85 Avg loss: 0.5423\n",
      "Training Results - Avg loss: 0.2089\n",
      "Training Results - Avg loss: 0.1642\n",
      "Training Results - Avg loss: 0.2157\n",
      "Training Results - Avg loss: 0.1981\n",
      "Training Results - Avg loss: 0.1393\n",
      "Training Results - Avg loss: 0.1632\n",
      "Training Results - Avg loss: 0.2427\n",
      "Training Results - Avg loss: 0.0903\n",
      "Training Results - Avg loss: 0.2305\n",
      "Training Results - Avg loss: 0.1590\n",
      "Training Results - Avg loss: 0.1694\n",
      "Training Results - Avg loss: 0.1346\n",
      "Training Results - Avg loss: 0.1825\n",
      "Training Results - Avg loss: 0.1506\n",
      "Training Results - Avg loss: 0.1997\n",
      "Training Results - Avg loss: 0.1515\n",
      "Training Results - Avg loss: 0.2722\n",
      "Training Results - Avg loss: 0.2176\n",
      "Training Results - Avg loss: 0.2048\n",
      "Training Results - Avg loss: 0.1245\n",
      "Training Results - Avg loss: 0.1994\n",
      "Training Results - Avg loss: 0.1890\n",
      "Training Results - Avg loss: 0.2244\n",
      "Training Results - Epoch: 28  Avg accuracy: 0.96 Avg loss: 0.1256\n",
      "Validation Results - Epoch: 28  Avg accuracy: 0.83 Avg loss: 0.5864\n",
      "Training Results - Avg loss: 0.1250\n",
      "Training Results - Avg loss: 0.1790\n",
      "Training Results - Avg loss: 0.1615\n",
      "Training Results - Avg loss: 0.1633\n",
      "Training Results - Avg loss: 0.1322\n",
      "Training Results - Avg loss: 0.2608\n",
      "Training Results - Avg loss: 0.1449\n",
      "Training Results - Avg loss: 0.2163\n",
      "Training Results - Avg loss: 0.1831\n",
      "Training Results - Avg loss: 0.2020\n",
      "Training Results - Avg loss: 0.2009\n",
      "Training Results - Avg loss: 0.2140\n",
      "Training Results - Avg loss: 0.1578\n",
      "Training Results - Avg loss: 0.1296\n",
      "Training Results - Avg loss: 0.1351\n",
      "Training Results - Avg loss: 0.1397\n",
      "Training Results - Avg loss: 0.1334\n",
      "Training Results - Avg loss: 0.2161\n",
      "Training Results - Avg loss: 0.2058\n",
      "Training Results - Avg loss: 0.1874\n",
      "Training Results - Avg loss: 0.2013\n",
      "Training Results - Avg loss: 0.1656\n",
      "Training Results - Avg loss: 0.2750\n",
      "Training Results - Epoch: 29  Avg accuracy: 0.96 Avg loss: 0.1117\n",
      "Validation Results - Epoch: 29  Avg accuracy: 0.84 Avg loss: 0.5471\n",
      "Training Results - Avg loss: 0.1331\n",
      "Training Results - Avg loss: 0.1584\n",
      "Training Results - Avg loss: 0.1551\n",
      "Training Results - Avg loss: 0.2276\n",
      "Training Results - Avg loss: 0.2351\n",
      "Training Results - Avg loss: 0.1720\n",
      "Training Results - Avg loss: 0.2094\n",
      "Training Results - Avg loss: 0.1194\n",
      "Training Results - Avg loss: 0.1675\n",
      "Training Results - Avg loss: 0.1633\n",
      "Training Results - Avg loss: 0.2034\n",
      "Training Results - Avg loss: 0.2339\n",
      "Training Results - Avg loss: 0.1628\n",
      "Training Results - Avg loss: 0.2860\n",
      "Training Results - Avg loss: 0.1637\n",
      "Training Results - Avg loss: 0.1663\n",
      "Training Results - Avg loss: 0.1689\n",
      "Training Results - Avg loss: 0.1669\n",
      "Training Results - Avg loss: 0.1345\n",
      "Training Results - Avg loss: 0.1865\n",
      "Training Results - Avg loss: 0.1262\n",
      "Training Results - Avg loss: 0.1875\n",
      "Training Results - Avg loss: 0.2211\n",
      "Training Results - Epoch: 30  Avg accuracy: 0.96 Avg loss: 0.1128\n",
      "Validation Results - Epoch: 30  Avg accuracy: 0.85 Avg loss: 0.5613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███</td></tr><tr><td>train_loss</td><td>█▇█▇▇▆▆▆▅▄▄▅▃▃▃▄▃▂▂▂▃▂▂▂▂▃▂▃▂▁▂▂▃▁▁▁▁▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▅▆▇▇▇▇▇▇████▇▇████████████</td></tr><tr><td>val_loss</td><td>█▇▆▄▃▂▂▁▃▂▂▁▁▁▁▁▁▃▃▂▃▃▃▃▂▄▄▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.9625</td></tr><tr><td>train_loss</td><td>0.11277</td></tr><tr><td>val_accuracy</td><td>0.84605</td></tr><tr><td>val_loss</td><td>0.56125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-leaf-50</strong> at: <a href='https://wandb.ai/ts-robustness/ml-course/runs/jees2fse' target=\"_blank\">https://wandb.ai/ts-robustness/ml-course/runs/jees2fse</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240226_205323-jees2fse\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize your model\n",
    "wandb.init(entity='ts-robustness', project='ml-course', config=config)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = TransformerClassification(config['model']).to(device)\n",
    "\n",
    "# Initialize your optimizer and criterion\n",
    "optimizer = build_optimizer(config, model)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x)\n",
    "        return y_pred, y\n",
    "\n",
    "train_evaluator = Engine(validation_step)\n",
    "val_evaluator = Engine(validation_step)\n",
    "\n",
    "# Attach metrics to the evaluators\n",
    "metrics = {\n",
    "    'accuracy': Accuracy(output_transform=lambda x: (x[0] > 0.5, x[1])),\n",
    "    'loss': Loss(criterion, output_transform=lambda x: (x[0], x[1].unsqueeze(1)))\n",
    "}\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(val_evaluator, name)\n",
    "\n",
    "### Logging\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(trainer):\n",
    "    batch_loss = trainer.state.output\n",
    "    print(\"Training Results - Avg loss: {:.4f}\".format(batch_loss))\n",
    "    wandb.log({\"train_loss\": batch_loss})\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_dataloader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.4f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['loss']))\n",
    "    wandb.log({\"train_accuracy\": metrics['accuracy'],\n",
    "               \"train_loss\": metrics['loss']})\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_dataloader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.4f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['loss']))\n",
    "    wandb.log({\"val_accuracy\": metrics['accuracy'],\n",
    "               \"val_loss\": metrics['loss']})\n",
    "\n",
    "# Run the training loop\n",
    "trainer.run(train_dataloader, max_epochs=config['train']['n_epoch'])\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in transformer_encoder: 434596\n",
      "Number of parameters in fc layer: 25101\n"
     ]
    }
   ],
   "source": [
    "# Count the number of parameters in the transformer_encoder layer\n",
    "transformer_encoder_params = sum(p.numel() for p in model.transformer_encoder.parameters())\n",
    "\n",
    "# Count the number of parameters in the fc layer\n",
    "fc_params = sum(p.numel() for p in model.fc.parameters())\n",
    "\n",
    "print(\"Number of parameters in transformer_encoder:\", transformer_encoder_params)\n",
    "print(\"Number of parameters in fc layer:\", fc_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_robustness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
