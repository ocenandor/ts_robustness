{
  "data": {
    "step": 50,
    "batch_size": 32,
    "seq_length": 150
  },
  "model": {
    "name": "transformer",
    "fc": {
      "dropout": 0.5834257267486305,
      "inner_dim": 100
    },
    "encoder": {
      "dropout": 0.3140066251525653,
      "activation": "gelu",
      "layer_norm_eps": 0.00742385988326984
    },
    "embedding": {
      "in_channels": 1,
      "out_channels": 16
    },
    "num_layers": 2
  },
  "train": {
    "lr": 0.00016174971317019094,
    "n_epoch": 30,
    "optimizer": "adam",
    "scheduler_config": {
      "type": null
    }
  },
  "random_state": 42
}